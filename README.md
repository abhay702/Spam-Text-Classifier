
# Data Analysis

This project entails a comprehensive analysis of a spam text dataset using Python, focusing on six key stages. Initially, we performed rigorous data cleaning to address inconsistencies and outliers. Following this, we conducted Exploratory Data Analysis (EDA) to gain insights into the distribution and characteristics of the data, visualizing key trends and patterns using various graphs. Subsequently, we undertook Text Preprocessing to prepare the text data for modeling, including tasks such as tokenization, stemming, and stop-word removal. Leveraging this preprocessed data, we proceeded to build predictive models aimed at accurately classifying spam messages. Through rigorous evaluation metrics and techniques, we assessed the performance of our models. Finally, based on the evaluation results, we iteratively refined our models to enhance their predictive capabilities, ensuring robustness and effectiveness in real-world scenarios. Throughout this process, visualizations played a pivotal role in elucidating insights and facilitating decision-making.


## Key Procedures 

# 1. Data cleaning
# 2. EDA - Exploratory data analysis
# 3. Text Preprocessing
# 4. Model building
# 5. Evaluation
# 6. Improvement
## Screenshots

![image](https://github.com/abhay702/Spam-data-analysis/assets/106369018/9fac2ea6-e1bf-4ec7-bc45-af73f1c3bfbe)

#Spam VS Ham

![image](https://github.com/abhay702/Spam-data-analysis/assets/106369018/fbe61783-15eb-4b79-b07a-8e84b9bb02df)

![image](https://github.com/abhay702/Spam-data-analysis/assets/106369018/7cd5bce0-c539-44cd-80dd-b5abed2bff8a)


## Learning :
### Data Cleaning:
- Hands-on experience in handling messy text data (missing values, duplicates, inconsistencies).
- Understanding the impact of data quality on model performance.

### Exploratory Data Analysis (EDA):
- Techniques for visualizing text data distributions and identifying patterns.
- Awareness of potential biases in the data and how to mitigate them.

### Text Preprocessing:
- Implementation of common text processing techniques like tokenization, stemming/lemmatization, and stop word removal.
- Analyzing the impact of preprocessing on model performance.

### Model Building:
- Evaluation of different machine learning models (e.g., Naive Bayes, Random Forest) for spam classification.
- Hyperparameter tuning to optimize model accuracy.

### Evaluation:
- Understanding and utilizing metrics like accuracy, precision, recall, and F1-score for text classification models.
- Visualization techniques (confusion matrix, ROC curve) to interpret model performance.

### Improvement:
- Iterative approach to refine the model by analyzing weaknesses and applying techniques like feature engineering or exploring alternative algorithms.

### Technical Skills Developed:
- Proficiency in Python libraries like pandas, scikit-learn, and NLTK for data manipulation, text processing, and model building.
- Importance of code documentation and project reproducibility.

This project provides a valuable hands-on experience in the entire data science workflow for text classification, from data cleaning to model improvement.


